{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-25T01:30:33.777600Z",
     "start_time": "2025-05-25T01:30:31.520536Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pytz\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "from scipy.signal import medfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "\n",
    "import synoptic\n",
    "\n",
    "from brc_tools.utils.lookups import _VRBLS\n",
    "\n",
    "# JRL: if problems, delete your existing config toml file\n",
    "# then create new one by uncommenting:\n",
    "# synoptic.configure(token=\"blah\")\n",
    "\n",
    "# Use Helvetica or Arial for plots\n",
    "plt.rcParams['font.family'] = 'Helvetica'\n",
    "plt.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 12\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'brc_tools'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 15\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msynoptic\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mbrc_tools\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mlookups\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _VRBLS\n\u001B[32m     17\u001B[39m \u001B[38;5;66;03m# JRL: if problems, delete your existing config toml file\u001B[39;00m\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# then create new one by uncommenting:\u001B[39;00m\n\u001B[32m     19\u001B[39m \u001B[38;5;66;03m# synoptic.configure(token=\"blah\")\u001B[39;00m\n\u001B[32m     20\u001B[39m \n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# Use Helvetica or Arial for plots\u001B[39;00m\n\u001B[32m     22\u001B[39m plt.rcParams[\u001B[33m'\u001B[39m\u001B[33mfont.family\u001B[39m\u001B[33m'\u001B[39m] = \u001B[33m'\u001B[39m\u001B[33mHelvetica\u001B[39m\u001B[33m'\u001B[39m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'brc_tools'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Importing observation data from Synoptic Weather as polars dataframe.\n",
    "We then save as json to send to our team's UBAIR website server.\n",
    "\n",
    "The plan goes as follows:\n",
    "- Import data from Synoptic Weather based on date, location, variable, etc\n",
    "- Export a json file from the polars (?) dataframe\n",
    "- Note the formatting so we can make the website read it in a predictable format\n",
    "\n",
    "First off: we want time series for multiple stations.\n",
    "\n",
    "Some of these data are noisy and/or with errors. We will filter some variables later."
   ],
   "id": "af3d6ad1c909760c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "stid_list = [\"KSLC\", \"UTORM\", \"CLN\", \"UTHEB\", \"UTCOP\", \"UTSTV\", \"UBHSP\", \"UB7ST\", \"UBCSP\",\n",
    "             # 'COOPDINU1', 'COOPROSU1',  'COOPVELU1',\n",
    "             'COOPFTDU1', 'COOPALMU1', 'COOPDSNU1', 'COOPNELU1',\n",
    "             ]\n",
    "data_root = \"./data\"\n",
    "data_fname = \"df_obs_pp.h5\"\n",
    "metadata_fname = \"df_metadata.h5\"\n",
    "df_obs_fpath = os.path.join(data_root, data_fname)\n",
    "df_meta_fpath = os.path.join(data_root, metadata_fname)\n",
    "\n",
    "start_date = datetime.datetime(2025, 1, 24, 0, 0, 0)\n",
    "end_date = datetime.datetime(2025, 2, 4, 0, 0, 0)\n",
    "# end_date = datetime.datetime(2025, 3, 16, 0, 0, 0)\n",
    "\n",
    "# df_meta = load_pickle(df_meta_fpath)\n",
    "# df_obs = pd.read_hdf(df_obs_fpath, key='df_obs')\n",
    "# df_obs_winter = df_obs[df_obs.index.month.isin([11, 12, 1, 2, 3])]\n"
   ],
   "id": "ad500ee0dd76dca0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def replace_max_values(df, vrbl, max_value=None):\n",
    "    # Assumes df is already filtered by stid.\n",
    "    if max_value is None:\n",
    "        max_value = df.select(pl.col(vrbl).max())[0, 0]\n",
    "    df = df.with_columns(\n",
    "        pl.when(pl.col(vrbl) == max_value)\n",
    "        .then(None)\n",
    "        .otherwise(pl.col(vrbl))\n",
    "        .alias(vrbl)\n",
    "    )\n",
    "    return df.with_columns(pl.col(vrbl).interpolate())\n",
    "\n",
    "def apply_median_filter(df, vrbl, kernel_size):\n",
    "    # Convert column to numpy array and apply median filter.\n",
    "    # Filtered by stid already\n",
    "    arr = df[vrbl].to_numpy().astype(\"float32\")\n",
    "    med_filtered = medfilt(arr, kernel_size=kernel_size)\n",
    "    return df.with_columns(pl.Series(name=vrbl, values=med_filtered))\n",
    "\n",
    "def filter_snow_depth(df, kernel_size):\n",
    "    # Run the preprocessing steps in sequence.\n",
    "    df = replace_max_values(df, \"snow_depth\")\n",
    "    df = apply_median_filter(df, \"snow_depth\", kernel_size=kernel_size)\n",
    "    return df\n",
    "\n",
    "def plot_snow_depth(ax, df, stid, kernel_size=5):\n",
    "    # Filter rows using Polars' filter method.\n",
    "    df_filtered = df.filter(pl.col(\"stid\") == stid)\n",
    "\n",
    "    if kernel_size is not None:\n",
    "        df_filtered = filter_snow_depth(df_filtered, kernel_size=kernel_size)\n",
    "        df_filtered = df_filtered.with_columns(pl.col(\"snow_depth\").interpolate())\n",
    "\n",
    "    # Convert time to Mountain Time Zone.\n",
    "    df_filtered = df_filtered.with_columns(pl.col(\"date_time\").dt.convert_time_zone(\"America/Denver\"))\n",
    "    # Make linestyle dashed if stid begins with \"COOP\"; else use solid\n",
    "    ls = \"--\" if stid.startswith(\"COOP\") else \"-\"\n",
    "    ax.plot(df_filtered[\"date_time\"], df_filtered[\"snow_depth\"], label=f\"{stid}\", alpha=0.5, lw=0.75,\n",
    "            linestyle=ls)\n",
    "\n"
   ],
   "id": "3d7c3db2e90c4e66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Collect all strings for the \"synoptic\" key from the nested dictionaries\n",
    "synoptic_vrbls = [\n",
    "    value['synoptic'] for value in _VRBLS.values()]"
   ],
   "id": "7127dd4008c3992d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_meta = synoptic.Metadata(stid=stid_list, verbose=True).df()\n",
    "df_meta"
   ],
   "id": "f72c1b9d6a7bdf23",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_data = synoptic.TimeSeries(stid=stid_list,start=start_date, end=end_date,\n",
    "                                 vars=synoptic_vrbls, verbose=True,\n",
    "                                 # rename_set_1=False, rename_value_1=False\n",
    "                                ).df().synoptic.pivot()\n",
    "df_data.head(20)"
   ],
   "id": "d6e17e9d97582721",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def clean_dataframe_for_json(df):\n",
    "    # If the dataframe is a Polars dataframe, convert it to Pandas.\n",
    "    if hasattr(df, \"to_pandas\"):\n",
    "        df = df.to_pandas()\n",
    "\n",
    "    # Replace NaN with None to become proper JSON null.\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # Clean string columns (remove unnecessary quotes).\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].str.strip('\"')\n",
    "\n",
    "    return df\n",
    "\n",
    "def export_data(df, filename, orient='records'):\n",
    "    df = clean_dataframe_for_json(df)\n",
    "\n",
    "    # Export to JSON.\n",
    "    with open(filename, 'w') as f:\n",
    "        json.dump(df.to_dict(orient=orient), f, default=str)\n",
    "\n",
    "    print(f\"Exported {len(df)} records to {filename}\")\n",
    "    return"
   ],
   "id": "31cf6f05b79bfe9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "export_data(df_data, \"data/df_obs_test.json\")\n",
    "\n",
    "# I might create one for a subsample (random) or subset by station, etc\n",
    "# Operationally on UBAIR site, we want  obs for map stations in last hour"
   ],
   "id": "8338681ee0816dfc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "583d166b1303e50c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Visuals",
   "id": "306be9f1cbbe75f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Plot snow depth for each station over time\n",
    "# Each station has a different reporting frequency and/or time, so plot independently\n",
    "# All stations are in Mountain Time Zone\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "for stid in stid_list:\n",
    "    # Skips here\n",
    "    # if stid in (\"KSLC\",):\n",
    "\n",
    "    # Plus for plot zooming\n",
    "    if stid in (\"KSLC\",\"UTCOP\",\"CLN\"):\n",
    "        continue\n",
    "\n",
    "    if stid.startswith(\"COOP\"):\n",
    "        ks = None\n",
    "        # But the snow 24h variable has 0.51 cm while depth has zero! It was cold!\n",
    "    else:\n",
    "        ks = 51\n",
    "    plot_snow_depth(ax, df_data, stid, kernel_size=ks)\n",
    "\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(_VRBLS[\"snow\"][\"label\"])\n",
    "ax.set_title(\"Case study 2024/2025: high ozone in UB\")\n",
    "\n",
    "# Light grey background\n",
    "ax.set_facecolor(\"#f0f0f0\")\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(False)\n",
    "plt.show()"
   ],
   "id": "853fa1a4bb638842",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
